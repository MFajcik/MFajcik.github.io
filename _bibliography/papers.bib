---
---

@inproceedings{fajcik2017automation,
    author = {Fajcik, Martin and Marcela Zachari{\'{a}}{\v{s}}ov{\'{a}} and Pavel	Smrz},
    title = {Automation of Processor Verification Using Recurrent Neural Networks},
    pages = {15--20},
    booktitle = {2017 18th International Workshop on Microprocessor and SOC Test and Verification (MTV)},
    year = {2017},
    location = {Austin, Texas, US},
    publisher = {Institute of Electrical and Electronics Engineers},
    ISBN = {978-1-5386-3351-9},
    doi = {10.1109/MTV.2017.15},
    language = {english},
    url = {http://www.fit.vutbr.cz/research/view_pub.php.cs?id=11512},
    html = {http://www.fit.vutbr.cz/research/view_pub.php.cs?id=11512},
    pdf = {https://arxiv.org/pdf/1803.09810.pdf},
    abstract = {When considering simulation-based verification of processors, the current trend is to generate stimuli using pseudorandom generators (PRGs), apply them to the processor inputs and monitor the achieved coverage of its functionality in order to determine verification completeness. Stimuli can have different forms, for example, they can be represented by bit vectors applied to the input ports of the processor or by programs that are loaded directly into the program memory. In this paper, we propose a new technique dynamically altering constraints for PRG via recurrent neural network, which receives a coverage feedback from the simulation of design under verification. For the demonstration purposes we used processors provided by Codasip as their coverage state space is reasonably big and differs for various kinds of processors. Nevertheless, techniques presented in this paper are widely applicable. The results of experiments show that not only the coverage closure is achieved much sooner, but we are able to isolate a small set of stimuli with high coverage that can be used for running regression tests.}
}

@inproceedings{fajcik-etal-2019-fit,
    title = "{BUT}-{FIT} at {S}em{E}val-2019 Task 7: Determining the Rumour Stance with Pre-Trained Deep Bidirectional Transformers",
    author = "Fajcik, Martin  and
      Smrz, Pavel  and
      Burget, Lukas",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2192",
    html = {https://aclanthology.org/S19-2192},
    pdf = {https://aclanthology.org/S19-2192.pdf},
    doi = "10.18653/v1/S19-2192",
    pages = "1097--1104",
    abstract = "This paper describes our system submitted to SemEval 2019 Task 7: RumourEval 2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell et al., 2019). The challenge focused on classifying whether posts from Twitter and Reddit support, deny, query, or comment a hidden rumour, truthfulness of which is the topic of an underlying discussion thread. We formulate the problem as a stance classification, determining the rumour stance of a post with respect to the previous thread post and the source thread post. The recent BERT architecture was employed to build an end-to-end system which has reached the F1 score of 61.67 {\%} on the provided test data. Without any hand-crafted feature, the system finished at the 2nd place in the competition, only 0.2 {\%} behind the winner.",
}

@inproceedings{fajcik-etal-2020-fit,
    title = "{BUT}-{FIT} at {S}em{E}val-2020 Task 5: Automatic Detection of Counterfactual Statements with Deep Pre-trained Language Representation Models",
    author = "Fajcik, Martin  and
      Jon, Josef  and
      Docekal, Martin  and
      Smrz, Pavel",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.53",
    html = {https://aclanthology.org/2020.semeval-1.53},
    pdf = {https://aclanthology.org/2020.semeval-1.53.pdf},
    pages = "437--444",
    abstract = "This paper describes BUT-FIT{'}s submission at SemEval-2020 Task 5: Modelling Causal Reasoning in Language: Detecting Counterfactuals. The challenge focused on detecting whether a given statement contains a counterfactual (Subtask 1) and extracting both antecedent and consequent parts of the counterfactual from the text (Subtask 2). We experimented with various state-of-the-art language representation models (LRMs). We found RoBERTa LRM to perform the best in both subtasks. We achieved the first place in both exact match and F1 for Subtask 2 and ranked second for Subtask 1.",
}

@inproceedings{docekal-etal-2020-jokemeter,
    title = "{J}oke{M}eter at {S}em{E}val-2020 Task 7: Convolutional Humor",
    author = "Docekal, Martin  and
      Fajcik, Martin  and
      Jon, Josef  and
      Smrz, Pavel",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.106",
    html = {https://aclanthology.org/2020.semeval-1.106},
    pdf = {https://aclanthology.org/2020.semeval-1.106.pdf},
    pages = "843--851",
    abstract = "This paper describes our system that was designed for Humor evaluation within the SemEval-2020 Task 7. The system is based on convolutional neural network architecture. We investigate the system on the official dataset, and we provide more insight to model itself to see how the learned inner features look.",
}

@inproceedings{jon-etal-2020-fit,
    title = "{BUT}-{FIT} at {S}em{E}val-2020 Task 4: Multilingual Commonsense",
    author = "Jon, Josef  and
      Fajcik, Martin  and
      Docekal, Martin  and
      Smrz, Pavel",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.46",
    html = {https://aclanthology.org/2020.semeval-1.46},
    pdf = {https://aclanthology.org/2020.semeval-1.46.pdf},
    pages = "374--390",
    abstract = "We participated in all three subtasks. In subtasks A and B, our submissions are based on pretrained language representation models (namely ALBERT) and data augmentation. We experimented with solving the task for another language, Czech, by means of multilingual models and machine translated dataset, or translated model inputs. We show that with a strong machine translation system, our system can be used in another language with a small accuracy loss. In subtask C, our submission, which is based on pretrained sequence-to-sequence model (BART), ranked 1st in BLEU score ranking, however, we show that the correlation between BLEU and human evaluation, in which our submission ended up 4th, is low. We analyse the metrics used in the evaluation and we propose an additional score based on model from subtask B, which correlates well with our manual ranking, as well as reranking method based on the same principle. We performed an error and dataset analysis for all subtasks and we present our findings.",
}

@article{fajcik2021pruning,
    title = {{P}runing the {I}ndex {C}ontents for {M}emory {E}fficient {O}pen-{D}omain {QA}},
    author = {Fajcik, Martin and Docekal, Martin and Ondrej, Karel and Smrz, Pavel},
    journal = {arXiv preprint arXiv:2102.10697},
    year = {2021},
    html = {https://arxiv.org/abs/2102.10697},
    pdf = {https://arxiv.org/pdf/2102.10697.pdf},
    abstract = {This work presents a novel pipeline that demonstrates what is achievable with a combined effort of state-of-the-art approaches. Specifically, it proposes the novel R2-D2 (Rank twice, reaD twice) pipeline composed of retriever, passage reranker, extractive reader, generative reader and a simple way to combine them. Furthermore, previous work often comes with a massive index of external documents that scales in the order of tens of GiB. This work presents a simple approach for pruning the contents of a massive index such that the open-domain QA system altogether with index, OS, and library components fits into 6GiB docker image while retaining only 8% of original index contents and losing only 3% EM accuracy.}
}

@inproceedings{pmlr-v133-min21a,
    title = {{N}eur{IPS} 2020 EfficientQA Competition: Systems, Analyses and Lessons Learned},
    author = {Min, Sewon and Boyd-Graber, Jordan and Alberti, Chris and Chen, Danqi and Choi, Eunsol and Collins, Michael and Guu, Kelvin and Hajishirzi, Hannaneh and Lee, Kenton and Palomaki, Jennimaria and Raffel, Colin and Roberts, Adam and Kwiatkowski, Tom and Lewis, Patrick and Wu, Yuxiang and K\"uttler, Heinrich and Liu, Linqing and Minervini, Pasquale and Stenetorp, Pontus and Riedel, Sebastian and Yang, Sohee and Seo, Minjoon and Izacard, Gautier and Petroni, Fabio and Hosseini, Lucas and Cao, Nicola De and Grave, Edouard and Yamada, Ikuya and Shimaoka, Sonse and Suzuki, Masatoshi and Miyawaki, Shumpei and Sato, Shun and Takahashi, Ryo and Suzuki, Jun and Fajcik, Martin and Docekal, Martin and Ondrej, Karel and Smrz, Pavel and Cheng, Hao and Shen, Yelong and Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng and Oguz, Barlas and Chen, Xilun and Karpukhin, Vladimir and Peshterliev, Stan and Okhonko, Dmytro and Schlichtkrull, Michael and Gupta, Sonal and Mehdad, Yashar and Yih, Wen-tau},
    booktitle = {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
    pages = {86--111},
    year = {2021},
    editor = {Escalante, Hugo Jair and Hofmann, Katja},
    volume = {133},
    series = {Proceedings of Machine Learning Research},
    month = {06--12 Dec},
    publisher = {PMLR},
    url = {https://proceedings.mlr.press/v133/min21a.html},
    html = "https://proceedings.mlr.press/v133/min21a.html",
    pdf = "https://proceedings.mlr.press/v133/min21a/min21a.pdf",
    abstract = {We review the EfficientQA competition from NeurIPS 2020. The competition focused on open-domain question answering (QA), where systems take natural language questions as input and return natural language answers. The aim of the competition was to build systems that can predict correct answers while also satisfying strict on-disk memory budgets. These memory budgets were designed to encourage contestants to explore the trade-off between storing retrieval corpora or the parameters of learned models. In this report, we describe the motivation and organization of the competition, review the best submissions, and analyze system predictions to inform a discussion of evaluation for open-domain QA. }
}

@inproceedings{fajcik2021r2d2,
    title = {R2-D2: A Modular Baseline for Open-Domain Question Answering},
    author = {Martin Fajcik and Martin Docekal and Karel Ondrej and Pavel Smrz},
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.findings-emnlp.73/",
    html = "https://aclanthology.org/2021.findings-emnlp.73/",
    pdf =  "https://aclanthology.org/2021.findings-emnlp.73.pdf",
    abstract = {This work presents a novel four-stage open-domain QA pipeline R2-D2 (Rank twice, reaD twice). The pipeline is composed of a retriever, passage reranker, extractive reader, generative reader and a mechanism that aggregates the final prediction from all system's components. We demonstrate its strength across three open-domain QA datasets: NaturalQuestions, TriviaQA and EfficientQA, surpassing state-of-the-art on the first two. Our analysis demonstrates that: (i) combining extractive and generative reader yields absolute improvements up to 5 exact match and it is at least twice as effective as the posterior averaging ensemble of the same models with different parameters, (ii) the extractive reader with fewer parameters can match the performance of the generative reader on extractive QA datasets.}
}


@inproceedings{fajcik-etal-2021-rethinking,
    title = "Rethinking the Objectives of Extractive Question Answering",
    author = "Fajcik, Martin  and
      Jon, Josef  and
      Smrz, Pavel",
    booktitle = "Proceedings of the 3rd Workshop on Machine Reading for Question Answering",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.mrqa-1.2",
    html = "https://aclanthology.org/2021.mrqa-1.2",
    pdf = "https://aclanthology.org/2021.mrqa-1.2.pdf",
    doi = "10.18653/v1/2021.mrqa-1.2",
    pages = "14--27",
    abstract = "This work demonstrates that using the objective with independence assumption for modelling the span probability P (a{\_}s , a{\_}e ) = P (a{\_}s )P (a{\_}e) of span starting at position a{\_}s and ending at position a{\_}e has adverse effects. Therefore we propose multiple approaches to modelling joint probability P (a{\_}s , a{\_}e) directly. Among those, we propose a compound objective, composed from the joint probability while still keeping the objective with independence assumption as an auxiliary objective. We find that the compound objective is consistently superior or equal to other assumptions in exact match. Additionally, we identified common errors caused by the assumption of independence and manually checked the counterpart predictions, demonstrating the impact of the compound objective on the real examples. Our findings are supported via experiments with three extractive QA models (BIDAF, BERT, ALBERT) over six datasets and our code, individual results and manual analysis are available online.",
}


@inproceedings{burdisso-etal-2022-idiapers,
    title = "{IDIAP}ers @ Causal News Corpus 2022: Efficient Causal Relation Identification Through a Prompt-based Few-shot Approach",
    author = "Burdisso, Sergio  and
      Zuluaga-gomez, Juan Pablo  and
      Villatoro-tello, Esau  and
      Fajcik, Martin  and
      Singh, Muskaan  and
      Smrz, Pavel  and
      Motlicek, Petr",
    booktitle = "Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.case-1.9",
    html = "https://aclanthology.org/2022.case-1.9",
    pdf = "https://aclanthology.org/2022.case-1.9.pdf",
    pages = "61--69",
    abstract = "In this paper, we describe our participation in the subtask 1 of CASE-2022, Event Causality Identification with Casual News Corpus. We address the Causal Relation Identification (CRI) task by exploiting a set of simple yet complementary techniques for fine-tuning language models (LMs) on a few annotated examples (i.e., a few-shot configuration).We follow a prompt-based prediction approach for fine-tuning LMs in which the CRI task is treated as a masked language modeling problem (MLM). This approach allows LMs natively pre-trained on MLM tasks to directly generate textual responses to CRI-specific prompts.We compare the performance of this method against ensemble techniques trained on the entire dataset.Our best-performing submission was fine-tuned with only 256 instances per class, 15.7{\%} of the all available data, and yet obtained the second-best precision (0.82), third-best accuracy (0.82), and an F1-score (0.85) very close to what was reported by the winner team (0.86).",
}

@inproceedings{fajcik-etal-2022-idiapers,
    title = "{IDIAP}ers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model",
    author = "Fajcik, Martin  and
      Singh, Muskaan  and
      Zuluaga-gomez, Juan Pablo  and
      Villatoro-tello, Esau  and
      Burdisso, Sergio  and
      Motlicek, Petr  and
      Smrz, Pavel",
    booktitle = "Proceedings of the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE)",
    month = dec,
    year = "2022",
    address = "Abu Dhabi, United Arab Emirates (Hybrid)",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2022.case-1.10",
    html = "https://aclanthology.org/2022.case-1.10",
    pdf = "https://aclanthology.org/2022.case-1.10.pdf",
    pages = "70--78",
    abstract = "In this paper, we describe our shared task submissions for Subtask 2 in CASE-2022, Event Causality Identification with Casual News Corpus. The challenge focused on the automatic detection of all cause-effect-signal spans present in the sentence from news-media. We detect cause-effect-signal spans in a sentence using T5 {---} a pre-trained autoregressive language model. We iteratively identify all cause-effect-signal span triplets, always conditioning the prediction of the next triplet on the previously predicted ones. To predict the triplet itself, we consider different causal relationships such as cause→effect→signal. Each triplet component is generated via a language model conditioned on the sentence, the previous parts of the current triplet, and previously predicted triplets. Despite training on an extremely small dataset of 160 samples, our approach achieved competitive performance, being placed second in the competition. Furthermore, we show that assuming either cause→effect or effect→cause order achieves similar results.",
}
@inproceedings{fajcik-etal-2023-claim,
    title = "Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction",
    author = "Fajcik, Martin  and
      Motlicek, Petr  and
      Smrz, Pavel",
    booktitle = "Findings of the Association for Computational Linguistics: ACL 2023",
    month = jul,
    year = "2023",
    address = "Toronto, Canada",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2023.findings-acl.647",
    html = "https://aclanthology.org/2023.findings-acl.647",
    pdf = "https://aclanthology.org/2023.findings-acl.647.pdf",
    pages = "10184--10205",
    abstract = "We present Claim-Dissector: a novel latent variable model for fact-checking and analysis, which given a claim and a set of retrieved evidence jointly learns to identify: (i) the relevant evidences to the given claim (ii) the veracity of the claim. We propose to disentangle the per-evidence relevance probability and its contribution to the final veracity probability in an interpretable way {---} the final veracity probability is proportional to a linear ensemble of per-evidence relevance probabilities. In this way, the individual contributions of evidences towards the final predicted probability can be identified. In per-evidence relevance probability, our model can further distinguish whether each relevant evidence is supporting (S) or refuting (R) the claim. This allows to quantify how much the S/R probability contributes to final verdict or to detect disagreeing evidence. Despite its interpretable nature, our system achieves results competetive with state-of-the-art on the FEVER dataset, as compared to typical two-stage system pipelines, while using significantly fewer parameters. Furthermore, our analysis shows that our model can learn fine-grained relevance cues while using coarse-grained supervision and we demonstrate it in 2 ways. (i) We show that our model can achieve competitive sentence recall while using only paragraph-level relevance supervision. (ii) Traversing towards the finest granularity of relevance, we show that our model is capable of identifying relevance at the token level. To do this, we present a new benchmark TLR-FEVER focusing on token-level interpretability {---} humans annotate tokens in relevant evidences they considered essential when making their judgment. Then we measure how similar are these annotations to the tokens our model is focusing on.",
}
