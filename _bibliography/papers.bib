---
---

@inproceedings{fajcik2017automation,
  author = {Fajcik, Martin and Marcela Zachari{\'{a}}{\v{s}}ov{\'{a}} and Pavel	Smrz},
   title = {Automation of Processor Verification Using Recurrent Neural Networks},
   pages = {15--20},
   booktitle = {2017 18th International Workshop on Microprocessor and SOC Test and Verification (MTV)},
   year = {2017},
   location = {Austin, Texas, US},
   publisher = {Institute of Electrical and Electronics Engineers},
   ISBN = {978-1-5386-3351-9},
   doi = {10.1109/MTV.2017.15},
   language = {english},
   url = {http://www.fit.vutbr.cz/research/view_pub.php.cs?id=11512},
   abstract = 	 {When considering simulation-based verification of processors, the current trend is to generate stimuli using pseudorandom generators (PRGs), apply them to the processor inputs and monitor the achieved coverage of its functionality in order to determine verification completeness. Stimuli can have different forms, for example, they can be represented by bit vectors applied to the input ports of the processor or by programs that are loaded directly into the program memory. In this paper, we propose a new technique dynamically altering constraints for PRG via recurrent neural network, which receives a coverage feedback from the simulation of design under verification. For the demonstration purposes we used processors provided by Codasip as their coverage state space is reasonably big and differs for various kinds of processors. Nevertheless, techniques presented in this paper are widely applicable. The results of experiments show that not only the coverage closure is achieved much sooner, but we are able to isolate a small set of stimuli with high coverage that can be used for running regression tests.}
}
@inproceedings{fajcik-etal-2019-fit,
    title = "{BUT}-{FIT} at {S}em{E}val-2019 Task 7: Determining the Rumour Stance with Pre-Trained Deep Bidirectional Transformers",
    author = "Fajcik, Martin  and
      Smrz, Pavel  and
      Burget, Lukas",
    booktitle = "Proceedings of the 13th International Workshop on Semantic Evaluation",
    month = jun,
    year = "2019",
    address = "Minneapolis, Minnesota, USA",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/S19-2192",
    doi = "10.18653/v1/S19-2192",
    pages = "1097--1104",
    abstract = "This paper describes our system submitted to SemEval 2019 Task 7: RumourEval 2019: Determining Rumour Veracity and Support for Rumours, Subtask A (Gorrell et al., 2019). The challenge focused on classifying whether posts from Twitter and Reddit support, deny, query, or comment a hidden rumour, truthfulness of which is the topic of an underlying discussion thread. We formulate the problem as a stance classification, determining the rumour stance of a post with respect to the previous thread post and the source thread post. The recent BERT architecture was employed to build an end-to-end system which has reached the F1 score of 61.67 {\%} on the provided test data. Without any hand-crafted feature, the system finished at the 2nd place in the competition, only 0.2 {\%} behind the winner.",
}

@inproceedings{fajcik-etal-2020-fit,
    title = "{BUT}-{FIT} at {S}em{E}val-2020 Task 5: Automatic Detection of Counterfactual Statements with Deep Pre-trained Language Representation Models",
    author = "Fajcik, Martin  and
      Jon, Josef  and
      Docekal, Martin  and
      Smrz, Pavel",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.53",
    pages = "437--444",
    abstract = "This paper describes BUT-FIT{'}s submission at SemEval-2020 Task 5: Modelling Causal Reasoning in Language: Detecting Counterfactuals. The challenge focused on detecting whether a given statement contains a counterfactual (Subtask 1) and extracting both antecedent and consequent parts of the counterfactual from the text (Subtask 2). We experimented with various state-of-the-art language representation models (LRMs). We found RoBERTa LRM to perform the best in both subtasks. We achieved the first place in both exact match and F1 for Subtask 2 and ranked second for Subtask 1.",
}

@inproceedings{docekal-etal-2020-jokemeter,
    title = "{J}oke{M}eter at {S}em{E}val-2020 Task 7: Convolutional Humor",
    author = "Docekal, Martin  and
      Fajcik, Martin  and
      Jon, Josef  and
      Smrz, Pavel",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.106",
    pages = "843--851",
    abstract = "This paper describes our system that was designed for Humor evaluation within the SemEval-2020 Task 7. The system is based on convolutional neural network architecture. We investigate the system on the official dataset, and we provide more insight to model itself to see how the learned inner features look.",
}

@inproceedings{jon-etal-2020-fit,
    title = "{BUT}-{FIT} at {S}em{E}val-2020 Task 4: Multilingual Commonsense",
    author = "Jon, Josef  and
      Fajcik, Martin  and
      Docekal, Martin  and
      Smrz, Pavel",
    booktitle = "Proceedings of the Fourteenth Workshop on Semantic Evaluation",
    month = dec,
    year = "2020",
    address = "Barcelona (online)",
    publisher = "International Committee for Computational Linguistics",
    url = "https://aclanthology.org/2020.semeval-1.46",
    pages = "374--390",
    abstract = "We participated in all three subtasks. In subtasks A and B, our submissions are based on pretrained language representation models (namely ALBERT) and data augmentation. We experimented with solving the task for another language, Czech, by means of multilingual models and machine translated dataset, or translated model inputs. We show that with a strong machine translation system, our system can be used in another language with a small accuracy loss. In subtask C, our submission, which is based on pretrained sequence-to-sequence model (BART), ranked 1st in BLEU score ranking, however, we show that the correlation between BLEU and human evaluation, in which our submission ended up 4th, is low. We analyse the metrics used in the evaluation and we propose an additional score based on model from subtask B, which correlates well with our manual ranking, as well as reranking method based on the same principle. We performed an error and dataset analysis for all subtasks and we present our findings.",
}

@article{fajcik2021pruning,
  title={Pruning the Index Contents for Memory Efficient Open-Domain QA},
  author={Fajcik, Martin and Docekal, Martin and Ondrej, Karel and Smrz, Pavel},
  journal={arXiv preprint arXiv:2102.10697},
  year={2021},
  abstract = 	  {This work presents a novel pipeline that demonstrates what is achievable with a combined effort of state-of-the-art approaches. Specifically, it proposes the novel R2-D2 (Rank twice, reaD twice) pipeline composed of retriever, passage reranker, extractive reader, generative reader and a simple way to combine them. Furthermore, previous work often comes with a massive index of external documents that scales in the order of tens of GiB. This work presents a simple approach for pruning the contents of a massive index such that the open-domain QA system altogether with index, OS, and library components fits into 6GiB docker image while retaining only 8% of original index contents and losing only 3% EM accuracy.}
}

@inproceedings{pmlr-v133-min21a,
  title = 	 {NeurIPS 2020 EfficientQA Competition: Systems, Analyses and Lessons Learned},
  author =       {Min, Sewon and Boyd-Graber, Jordan and Alberti, Chris and Chen, Danqi and Choi, Eunsol and Collins, Michael and Guu, Kelvin and Hajishirzi, Hannaneh and Lee, Kenton and Palomaki, Jennimaria and Raffel, Colin and Roberts, Adam and Kwiatkowski, Tom and Lewis, Patrick and Wu, Yuxiang and K\"uttler, Heinrich and Liu, Linqing and Minervini, Pasquale and Stenetorp, Pontus and Riedel, Sebastian and Yang, Sohee and Seo, Minjoon and Izacard, Gautier and Petroni, Fabio and Hosseini, Lucas and Cao, Nicola De and Grave, Edouard and Yamada, Ikuya and Shimaoka, Sonse and Suzuki, Masatoshi and Miyawaki, Shumpei and Sato, Shun and Takahashi, Ryo and Suzuki, Jun and Fajcik, Martin and Docekal, Martin and Ondrej, Karel and Smrz, Pavel and Cheng, Hao and Shen, Yelong and Liu, Xiaodong and He, Pengcheng and Chen, Weizhu and Gao, Jianfeng and Oguz, Barlas and Chen, Xilun and Karpukhin, Vladimir and Peshterliev, Stan and Okhonko, Dmytro and Schlichtkrull, Michael and Gupta, Sonal and Mehdad, Yashar and Yih, Wen-tau},
  booktitle = 	 {Proceedings of the NeurIPS 2020 Competition and Demonstration Track},
  pages = 	 {86--111},
  year = 	 {2021},
  editor = 	 {Escalante, Hugo Jair and Hofmann, Katja},
  volume = 	 {133},
  series = 	 {Proceedings of Machine Learning Research},
  month = 	 {06--12 Dec},
  publisher =    {PMLR},
  url = 	 {https://proceedings.mlr.press/v133/min21a.html},
  abstract = 	 {We review the EfficientQA competition from NeurIPS 2020. The competition focused on open-domain question answering (QA), where systems take natural language questions as input and return natural language answers.  The aim of the competition was to build systems that can predict correct answers while also satisfying strict on-disk memory budgets. These memory budgets were designed to encourage contestants to  explore  the  trade-off between storing retrieval corpora or the parameters of learned models. In this report, we describe the motivation and organization of the competition, review the best submissions, and analyze system predictions to inform a discussion of evaluation for open-domain QA. }
}

@inproceedings{fajcik2021r2d2,
    title={R2-D2: A Modular Baseline for Open-Domain Question Answering}, 
    author={Martin Fajcik and Martin Docekal and Karel Ondrej and Pavel Smrz},
    booktitle = "Findings of the Association for Computational Linguistics: EMNLP 2021",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "http://arxiv.org/abs/2109.03502",
    abstract = {This work presents a novel four-stage open-domain QA pipeline R2-D2 (Rank twice, reaD twice). The pipeline is composed of a retriever, passage reranker, extractive reader, generative reader and a mechanism that aggregates the final prediction from all system's components. We demonstrate its strength across three open-domain QA datasets: NaturalQuestions, TriviaQA and EfficientQA, surpassing state-of-the-art on the first two. Our analysis demonstrates that: (i) combining extractive and generative reader yields absolute improvements up to 5 exact match and it is at least twice as effective as the posterior averaging ensemble of the same models with different parameters, (ii) the extractive reader with fewer parameters can match the performance of the generative reader on extractive QA datasets.}
}


@inproceedings{fajcik2021rethinking,
    title = "Rethinking the Objectives of Extractive Question Answering",
    author = "Fajcik, Martin  and
      Josef, Jon  and
      Pavel, Smrz",
    booktitle = "Proceedings of the 3rd Workshop on Machine Reading for Question Answering",
    month = nov,
    year = "2021",
    address = "Punta Cana, Dominican Republic",
    publisher = "Association for Computational Linguistics",
    url = "https://arxiv.org/pdf/2008.12804.pdf",
    abstract = "This work demonstrates that using the objective with independence assumption for modelling the span probability P(a_s,a_e)=P(a_s)P(a_e) of span starting at position as and ending at position ae has adverse effects. Therefore we propose multiple approaches to modelling joint probability P(a_s,a_e) directly. Among those, we propose a compound objective, composed from the joint probability while still keeping the objective with independence assumption as an auxiliary objective. We find that the compound objective is consistently superior or equal to other assumptions in exact match. Additionally, we identified common errors caused by the assumption of independence and manually checked the counterpart predictions, demonstrating the impact of the compound objective on the real examples. Our findings are supported via experiments with three extractive QA models (BIDAF, BERT, ALBERT) over six datasets and our code, individual results and manual analysis are available online.",
}
@misc{https://doi.org/10.48550/arxiv.2207.14116,
  doi = {10.48550/ARXIV.2207.14116},  
  url = {https://arxiv.org/abs/2207.14116},
  author = {Fajcik, Martin and Motlicek, Petr and Smrz, Pavel},
  keywords = {Computation and Language (cs.CL), Artificial Intelligence (cs.AI), FOS: Computer and information sciences, FOS: Computer and information sciences},
  title = {Claim-Dissector: An Interpretable Fact-Checking System with Joint Re-ranking and Veracity Prediction},
  publisher = {arXiv},
  year = {2022},
  copyright = {Creative Commons Attribution Non Commercial Share Alike 4.0 International}
}

